{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# reload notebook automatically after changes to source python files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# change base folder to parent\n",
    "import os\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "from tf_utils import compose_tf_matrix\n",
    "# from src.utils.colmap.read_write_model import read_images_binary\n",
    "\n",
    "# for evo ######################################################################\n",
    "from evo.core import metrics\n",
    "# from evo.core.units import Unit\n",
    "\n",
    "from evo.tools import log\n",
    "log.configure_logging(verbose=False, debug=False, silent=True)\n",
    "\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "from evo.tools import plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# temporarily override some package settings\n",
    "from evo.tools.settings import SETTINGS\n",
    "SETTINGS.plot_usetex = False\n",
    "\n",
    "plot.apply_settings(SETTINGS)\n",
    "\n",
    "from evo.tools import file_interface\n",
    "import copy\n",
    "#############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_path = Path(\"/scratch/kumaraditya_gupta/Datasets/TorWIC-SLAM/Jun15/Aisle_CCW_Run_1\")\n",
    "\n",
    "experiment_path = Path(\"/scratch/rohit_jayanti/indoor-topo-loc/hloc_experiments/torwic_sfm_superpoint_inloc_superpoint+lightglue_netvlad_exhaustive\")\n",
    "model_name = \"sfm_superpoint+lightglue_down3\"\n",
    "\n",
    "outputs = Path(f\"/scratch/rohit_jayanti/indoor-topo-loc/hloc_experiments/torwic_eval_trajectory/{experiment_path.name}_{model_name}\")\n",
    "if outputs.exists():\n",
    "    shutil.rmtree(outputs)\n",
    "outputs.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gt_poses_path = scenario_path / 'traj_gt.txt'\n",
    "gt_poses = gt_poses_path.read_text().splitlines()\n",
    "gt_poses_list = np.array([list(map(float, pose.split())) for pose in gt_poses])\n",
    "\n",
    "DOWNSAMPLE = 3\n",
    "gt_poses_list = gt_poses_list[::DOWNSAMPLE]\n",
    "\n",
    "num_poses = len(gt_poses_list)\n",
    "print(f\"Number of poses: {num_poses}\")\n",
    "\n",
    "START_POSE = 0\n",
    "END_POSE = num_poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Ground Truth Image poses and writing to KITTI Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image_right\n",
    "qvec_l2c = np.array([0.41406507, -0.6100328, 0.57049433, -0.3618651])\n",
    "tvec_l2c = np.array([0.07686256, -0.15441064, -0.1026438])\n",
    "tf_l2c = compose_tf_matrix(qvec_l2c, tvec_l2c, fix_qvec=True)\n",
    "\n",
    "image_gt_poses_list = []\n",
    "for i in tqdm.tqdm(range(START_POSE, END_POSE)):   \n",
    "\n",
    "    # read pose - Ouster Lidar\n",
    "    qvec_w2l = np.array(gt_poses_list[i][4:8])\n",
    "    tvec_w2l =  np.array(gt_poses_list[i][1:4])\n",
    "    tf_w2l= compose_tf_matrix(qvec_w2l, tvec_w2l, fix_qvec=True)\n",
    "\n",
    "    tf_w2c = tf_w2l @ tf_l2c\n",
    "    image_gt_poses_list.append(tf_w2c)\n",
    "    \n",
    "image_gt_poses_kitti = np.array([pose[:3, :].reshape(-1) for pose in image_gt_poses_list])\n",
    "gt_poses_file = outputs / 'gt_image_right_poses.txt'\n",
    "\n",
    "np.savetxt(gt_poses_file, image_gt_poses_kitti, fmt='%.6f')\n",
    "print(f'> Saved GT camera poses to {gt_poses_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Estimated Poses from COLMAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_dir = experiment_path / model_name\n",
    "assert sfm_dir.exists(), f\"Path does not exist: {sfm_dir}\"\n",
    "print(f\"Reading COLMAP model from {sfm_dir}\")\n",
    "\n",
    "pred_images = read_images_binary(sfm_dir / 'images.bin')\n",
    "\n",
    "image_pred_poses_list = []\n",
    "\n",
    "for i in tqdm.tqdm(range(START_POSE, END_POSE)):   \n",
    "    pred_image = pred_images[i+1]\n",
    "    qvec_c2w = pred_image.qvec\n",
    "    tvec_c2w = pred_image.tvec\n",
    "    \n",
    "    tf_c2w = compose_tf_matrix(qvec_c2w, tvec_c2w, fix_qvec=False)\n",
    "    tf_w2c = np.linalg.inv(tf_c2w)\n",
    "    image_pred_poses_list.append(tf_w2c)\n",
    "\n",
    "# UNCOMMENT THIS TO SCALE THE PREDICTED TRAJECTORY positions using GT as reference\n",
    "# for i in tqdm.tqdm(range(START_POSE+1, END_POSE)):   \n",
    "#     image_pred_poses_list[i][:3, 3] *= np.linalg.norm(image_gt_poses_list[i][:3, 3]) / np.linalg.norm(image_pred_poses_list[i][:3, 3])\n",
    "\n",
    "\n",
    "image_pred_poses_kitti = np.array([pose[:3, :].reshape(-1) for pose in image_pred_poses_list])\n",
    "pred_poses_file = outputs / 'pred_image_right_poses.txt' \n",
    "\n",
    "np.savetxt(pred_poses_file, image_pred_poses_kitti, fmt='%.6f')\n",
    "print(f'> Saved estimated camera poses to {pred_poses_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(image_gt_poses_kitti) == len(image_pred_poses_kitti), \"Number of poses do not match\"\n",
    "print(f\"Number of poses: {len(image_gt_poses_kitti)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the estimated poses using the EVO toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "traj_ref = file_interface.read_kitti_poses_file(str(gt_poses_file))\n",
    "traj_est = file_interface.read_kitti_poses_file(str(pred_poses_file))\n",
    "print(f\"Trajectory ref scale: {traj_ref.scale}\")\n",
    "\n",
    "EYEBALL_SCALE = 8.0\n",
    "\n",
    "traj_est_aligned = copy.deepcopy(traj_est)\n",
    "traj_est_aligned.align(traj_ref, correct_scale=True, correct_only_scale=False)\n",
    "traj_est_aligned.align_origin(traj_ref)\n",
    "traj_est_aligned.scale(EYEBALL_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 20))\n",
    "traj_by_label = {\n",
    "    \"reference\": traj_ref, \n",
    "    \"estimate (not aligned)\": traj_est,\n",
    "    \"estimate (aligned)\": traj_est_aligned,\n",
    "    # \"estimate (aligned and scaled w/gt)\": traj_est_scaled_aligned,\n",
    "}\n",
    "\n",
    "\n",
    "plot.trajectories(fig, traj_by_label, plot.PlotMode.xy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_relation = metrics.PoseRelation.translation_part\n",
    "use_aligned_trajectories = True\n",
    "\n",
    "if use_aligned_trajectories:\n",
    "    data = (traj_ref, traj_est_aligned) \n",
    "else:\n",
    "    data = (traj_ref, traj_est)\n",
    "\n",
    "ape_metric = metrics.APE(pose_relation)\n",
    "ape_metric.process_data(data)\n",
    "\n",
    "ape_stats = ape_metric.get_all_statistics()\n",
    "pprint.pprint(ape_stats)\n",
    "\n",
    "# create an x array with the time in seconds corresponding to each pose\n",
    "seconds_from_start = list(range(START_POSE, END_POSE))\n",
    "\n",
    "fig = plt.figure()\n",
    "plot.error_array(fig.gca(), ape_metric.error, x_array=seconds_from_start,\n",
    "                statistics={s:v for s,v in ape_stats.items() if s != \"sse\"},\n",
    "                name=\"APE\", title=\"APE w.r.t. \" + ape_metric.pose_relation.value, xlabel=\"$t$ (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mode = plot.PlotMode.xy\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = plot.prepare_axis(fig, plot_mode)\n",
    "plot.traj(ax, plot_mode, traj_ref, '--', \"gray\", \"reference\")\n",
    "plot.traj_colormap(ax, traj_est_aligned if use_aligned_trajectories else traj_est, ape_metric.error, plot_mode, min_map=ape_stats[\"min\"], max_map=ape_stats[\"max\"])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hloc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
